# 데이터 로드와 텍스트 분할

## 문서 로더

: 우리가 가진 다양한 파일 형식의 문서를 데이터 베이스에 불러오는 역할을 합니다.

### document 객체

document란 랭체인의 기본 문서 객체이다. 다양한 형식의 문서 파일을 불러오면 document 형식으로 로드된다.

---

트렌스포머 모델을 모든 개발자들이 알아야 하나?

너무 금방 구닥다리가 된다. LLM을 공부할거라면, 최신 기법만 배워라.

---

임베딩이란 무엇인가?
레그, LLM에서 임베딩이라는 말을 쓴다.

(말뭉치 학습)기초 데이터셋을 학습하면 그 결과로
토큰을 추출하고
토큰별 벡터를 특정 차원으로 만든다

(백터를 어레이로 이해하고, 어레이의 length라고 생각해도 ㅇㅋ)

차원에 들어가는 값은 신경망 학습을 통해 의미를 갖게 되는 것임.

안녕하세요 -> 토큰화 [안녕, 하세요] (신경망이 토큰화함)

학습량이 적을수록 의미론적인 토크나이징 불가 ㅜㅡㅜ

-> {안녕: [12,14,20], 하세요:[103,3,15]} 이 숫자는 신경망이 역전파 행렬 변수의 계산을 통해 계산한거임 (편미분 그라데이션) 왜 이게 나왔는지는 몰라도됨

-> 각 토큰을 특정 차원의 백터로 만든다. 이 숫자 세 개 안에 여러 의미가 담기는데, 현대의 모델들은 토큰 하나당 8천개 이상의 차원을 갖게 만든다. GPT4는 차원이 만천오백 임. 차원이 적으면 의미를 내포할 . 수있는 차원이 적은거임!
-> 모든 토큰이 백터를 갖는 것을 >>임베딩<<이라고 한다.

- 모든 토큰은 동일 차원의 벡터가 되며 특정 차원은 같은 시맨틱을 갖게 됨.
- 저기서 14와 3이 같은 의미 필드인거임. 우리는 모름

- 컴퓨터는 토큰을 여러 의미가 부여된 숫자의 집합(벡터)로 인식할 수 있음

통상 LLM모델은 토큰마다 다른 백터를 가지고 있음. 토큰에 각각 백터르르 이용해서 뭔가 백터를 만든다.

e.g.

코드스피츠는 스터디그룹 -> 크드스피츠, 는, 스터디, 그룹 -> 동일 차원의 백터 4개로 바뀜 -> attention + FFN 공정을 여러 단계로 거침

FFN은 알아둘 필요가 있음.

차원이 세 개인 백터로 되어 있는데, 차원을 4배로 넓히면 (12개) 일부 값을 비선형 필터링 함수로 제거하면, 일부는 0이 된다. 그 다음에 다시 3개로 압축함. 이걸 의미론적으로 생각해보면, 같은 차원의 숫자를 4개로 나눠서, (차원 넓힘) 필터링을 하고, 다시 그 것을 줄이면서 의미를 필터링할 기회를 줌. (신경망 네트워킹 이라고 부른다.) -> 마지막 토큰만 건진다. (어레이의 마지막 숫자들만 건짐. ) 유사도가 가장 비슷한 애를 찾아서 그걸 출력하는 것임.

이 짓을 현대의 트랜스폼 모델은 여러 차원 함.

-> '입니다' 가 나옴 (pooling)

RAG의 임베딩

1. 모든 토큰의 백터를 pooling을 통해서 결합한 값
2. 토큰 하나가 2096차원인 경우, 토큰이 100개 있어도, 결과는 4096차원임. 코드스피츠는 스터디 그룹입니다 > 임베딩하면 ??
3. 토큰의 차원은 시맨틱 공간이므로 여러 토큰의 결합으로 시맨틱이 강화됨
4. 이렇게 토큰 결합을 semantic aggregation이라 하고 방법을 pooling이라 함.
   - 산술평균 mean pooling
   - 최대값 max pooling
   - 어텐션 가중치 attention-weighted pooling

래그의 임베딩은 의미있는 토큰만 학습함. 조사 등은 거의 0임

5. 단순히 모든 토큰을 합치는 이유는 이미 엠베딩 모델 학습시 토큰이 여러 문장에서 학습되어 차원에 반영되어 있기 때문

임베딩에는 비용 많이 안든다.

코드스피츠는 스터디그룹 -> 크드스피츠, 는, 스터디, 그룹 -> 는 은 0임 -> pooling 때림 -> 숫자 나옴 -> 리트리버 -> 비슷한 백터 발견 -> 그 백터에 연결된 문서 얻기

문장 전체를 하나의 토큰 사이즈에 맞는 백터로 환원시킴.

---

임베딩 모델이 중요한건 알겠음.
이 기본편 책만 이해해도 레그를 잘 구현할 . 수있는 기법 충분하지만, 원리는 설명 안해줌

1. 임베딩 모델은 LLM과 완전히 다르게 학습됨.
   a. LLM은 각 토큰은 문맥과 위치를 고려하여 다음 토큰을 예상하도록 학습
   b. rag - 풀링을 통한 토큰결합 벡터가 시멘틱이 부합되도록 학습 > 결합 결과가 내 가 원하는 시멘틱이랑 맞네~ 이렇게 학습됨. 학습 구조가 다름

2. 임베딩모델의 토큰 백터 차원 < LLM 모델 토큰 백터 차원
   왜 제미나이 라이트 등이 잘 도는거지? 전체 모델 파라미터 수는 낮았지만, 토큰 공간을 넓혀놨음
   a. LLM용 토큰은 어텐션을 고려한 시멘틱 차원이 더 많이 필요
   b. RAG용 토큰은 모든 위치와 관계를 뭉쳐서 오직 의미적 중요성만 필요
   c. 보통 절반 크기. 2천대 임베딩차원은 LLM의 4천대 차원과 대등한 의미공간

3. 모델 학습데이터셋이 실사용에 큰 영향을 줌.
   a. 청크크기의 적절성 - 학습은 4문장단위로 했는데 청크는 20문장이면 희석 : 임베딩 모델이 학습한 토큰 사이즈를 기준으로 청크를 나눈다!
   b. 학습셋의 도메인 - 특정 분야로 토큰벡터가 조정되어있으면 다른 분야는 왜곡
   c. 문체 - 학습셋의 문체에 따라 적합성이 달라짐. 논문체, 소셜체, 상담체 등 => 학습한 문체의 영향을 받음! 그거랑 비슷한 문체로 물어봐야함
   d. 싱글 or 페어 - 질의에 매칭되는 페어, fact에 대응하는 싱글
   c.f. 몸에 해로운 음료는? 콜라, 사이다 로 학습하면 질문쪽에 부합하게 토큰벡터 생성 (질문에 유리하게 생성됨)
   콜라에 나쁜 성분이 있다로 백터값을 얻으면 -> 임베딩 불일치 / 콜라는 몸에 해롭나? -> 높은 임베딩 일치

거의 모든 애들은 . 다페어학습이 되어있음. 질문을 임베딩해서 일치도를 보는게 훨씬 좋음. pdf를 넣으면 . 내질문에 부합하게 안나옴 ㅠㅡㅠ 애당초 학습을 이렇게 했음

우리가 가지고 있는 사실은 다 팩트 기반이고 페어로 안 되어 있음.

---

희소백터

1. 주요 솔루션 - 엘라스틱서치, RDB 풀텍스트인덱싱, 윈도우 파일인덱싱 등
2. 벡터 디비 지원 - 하이브리드 질의 지원을 위해 내장함
3. 강점 - 질의를 백터로 변환하고 유사성을 계산하는 과정이 작은 비용으로 해결됨. BM25(TF-IDF변형)로 유사성을 평가함. CPU연산으로 충분
4. 단점 - 토큰이 추가삭제되면 재인덱싱 필요. 토큰수가 많아질수록 백터차원 증가

시스템 . 내모든 토큰
[0: 안녕, 1: 코드스피츠, 2: 스터디, 3: RAG]

데이터
[0, 2,2,1] - 코드스피츠는 스터디 그룹이며 코드스피츠는 최근 RAG 스터디를 진행 중
-> 몇 번 나왔는지 체크 = 문장 속 시스템이 부여한 토큰의 개수

사용자 질의 "RAG 공부 위한 스터디 추천해줘" > 빈도백터치환 > 유사도 비교(BM25사용)

---

밀집백터

1.  주요솔루션 - 백터디비, 포스트그리 백터지원, 엘라슽틱서치 백터지원
    ** 백터 검색 실무 가이드 ** 이 책 읽으세요 ~~~
2.  강점 - 질의를 의미론적으로 분석하여 유사한 정보를 가져옴
3.  단점 - 비용이 크고 의미부여에 따라 불일치 가능성이 높음
    ** 임베딩모델이 어떤 토큰 백터를 만들었는지가 킥임 이게 제일 중요함요 **

        a. 임베딩모델의 학습 구조와 구축된 데이터 구조의 불일치
        b. 임베딩모델의 학습 구조와 사용자 질의의 불일치
        c. 임베딩모델의 학습 구조와 도메인 불일치
        d. 임베딩모델의 학습 구조와 기타 의미론적인 어떤 것의 불일치 일체

4.  단점을 보강해야 의미론적 유사도가 정확해짐
    a. 질의 변형 - 질의를 임베딩 모델학습구조에 맞게 변형
    b. 데이터 변형 - 데이터를 임베딩 모델학습구조에 맞게 변형
    => 의미적 불일치를 줄이는 것이 RAG 운용의 핵심이다! ! ! 그래서 실무에서 레그 득을 받은 사람이 적은 이유... ㅜㅡㅜ
    => 이걸 튜닝하는 것이 개 짱 중요하다

5.  큰 유지보수 비용이 발생
    a. 자동화된 프로세스 필요
    b. 실행관련 비용과 정확성 사이에 트레이드 오프

6.  유사도 평가는 FAISS 사용. 내적을 정규화한 . 뒤코사인유사도사용(GPU 연산)
    > > 코사인 각도가 유사하도록 맞춘다 : 로짓(?)

---

유사도개선

1. 질의분해 - 모델학습셋과 비슷한 구조로 질의를 분해하거나 재작업 후 임베딩
2. 다중범주 - 다양한 관점으로 원본 데이터를 여러 개로 만들어 복합비교 (부모자식관계)
3. 하이브리드질의 - 키워드검색과 임베딩유사도를 동시 진행
4. 질의구조 - 데이터를 정해진 질의구조에 맞게 재작성하여 비교
5. 메타필드병합질의 - 본문과 무관한 필드값으로 질의한 결과와 복합비교(DB기능)

DB
dmbeding meta contents

-> 이렇게 메타데이터를 넣어놓을 . 수있음

a가 5이상인 스터디 그룹은? > 질의분해 > meta['a'] > + 합쳐가지고 질의답을 찾아내는것임

응답 시간 연장에 대한 고객의 인식 변화가 생김 ㅋㅋㅋ
