# RAG （Retrieval-Augmented Generation）

## 검색, 증강, 생성

## 할루시네이션(hallucination)

## 언어모델의 성능향상을 위한 각 기술의 난이도 순서

- Prompt Engineering
- RAG : 난이도에 비해 성능 향상 비율이 높음 (압도적 성능)/ 할루시네이션 감소에 가장 큰 영향을 미침
- PEFT
- FULL FINE TUNING

## LangChain을 이용한 RAG 시스템 구축

- LangChain: 대규모 언어 모델로 구동되는 애플리케이션을 개발하기 위한 프레임워크. GPT와 같은 언어 모델과 우리가 만들고자 하는 서비스를 쉽게 연결해주는 도구
  c.f. GPT를 이용하여 고객 응대 챗봇 만들기 등 GPT의 두뇌를 원하는 작업 흐름에 접목하여 체인으로 엮는 형태
- ChatGPT: GPT라는 언어 모델을 기반으로 한 대화형 AI 플랫폼

![](https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/blt1496b19e4c6f9e66/66ba412a46b3f4241b969f48/rag-in-action.jpeg)

## 리트리버(Retriever, 검색기)

: 해당 질문과 유사성이 높은 문서 찾아옴

다만, 정보에서 관련성 있는 정보만 리트리버에 전달하는 것이 필요 -> RAG 프로세스의 사전 단계

## 전처리 과정(사전단계) : 문서 로드- 텍스트 분할 - 임베딩- 저장

- 문서 로드 : 문서 로드 및 텍스트 분할
- 텍스트 분할 : 문서를 청크로 분할
  - 청크 오버랩: 청크 끝부분에서 맥락이 이어질 수 있도록 일부를 겹쳐서 분할
- 임베딩 : 청크를 컴퓨터가 이해할 수 있도록 임베딩
  - 임베딩이 비용이 들어가는 작업이기 때문에, 매번 할 수가 없어 DB에 저장
- 저장 : 임베딩된 청크를 DB에 저장

## 사전단계 이후의 실행 단계: 리트리버-프롬프트-LLM-체인생성

- 리트리버 : 질문이 주어지면, 이와 관련된 백터를 벡터 데이터베이스에서 검색함.
  - 사용자의 질문을 질문 벡터로 변환하고, 이 질문 벡터가 문서 벡터들과 비교되어 유사성이 계산됨. 이 과정에서 **코사인 유사도** 알고리즘 등 활용
  - 전체 시스템의 품질과 직결
- 프롬프트 : 검색된 정보를 바탕으로 언어 모델을 위한 질문을 구성함. 정보를 바탕으로 어떻게 질문할지를 결정하는 과정
- LLM : 구성된 프롬프트를 사용하여 언어 모델이 실제 답변을 생성함. 수집된 정보를 바탕으로 과제나 보고서를 작성하는 학생임.
- 체인생성 : 이전의 모든 과정을 하나의 파이프라인으로 묶어 주는 체인을 생성함
  - LCEL 문법 활용

## 토큰과 토큰화

- 토큰: 자연어 처리에서 텍스트를 처리하기 위해 나눈 작은 단위
- 토큰화: 텍스트를 토큰으로 나누는 과정

## 토큰화 방법

- 문자 기반 토큰화: 텍스트를 개별 문자로 쪼개어 각 문자를 하나의 토큰으로 취급하는 방식
  - c.f. hello -> 5개의 토큰으로 분리
- 단어 기반 토큰화: 텍스트를 단어 단위로 쪼개어 각 단어를 하나의 토큰으로 취급하는 방식
  - c.f. Hello, World! -> 4개의 토큰으로 분리

=> LLM은 먼저 나올 토큰을 생성하면 그 다음 나올 토큰을 확률적으로 계산하여 생성하는 로직을 가지고 있기 때문에, 문자 기반 토크화와 단어 기반 토큰화를 비교하면, 문자 기반 토큰화의 토큰이 많기 때문에 틀린 토큰을 생성할 가능성이 높음.

c.f. 12개의 토큰 예측이 4개의 토큰 예측보다 틀릴 확률이 높음. 문자 기반 토큰화가 예측을 더 많이 해야함.
더불어, 단어 기반 토큰화도 모든 단어를 저장한 단어 사전이 필요하기 때문에, 비효율적

- 서브워드 기반 토큰화: 단어를 처음에 문자 단위로 분해한 후, 자주 등장하는 문자 상을 결합해 더 큰 서브워드로 만드는 방식
  - 바이트 페어 인코딩(BFE) 알고리즘

## 토큰 사용량

- GPT 4.0 이하 버전의 경우, 한글른 영어보다 좀 더 토큰을 많이 소모함

## 모델의 입출력

- 컨텍스트 윈도우: 모델이 한 번에 처리하고 이해할 수 있는 전체 택스트의 문맥 범위
- 컨텍스트 길이: 한 번에 처리할 수 있는 입력과 출력의 총합 토큰 수
- max_tokens: 출력되는 최대 토큰 수
  - 출력이 길어질수록 입력으로 넣을 수 있는 텍스트의 양이 줄어든다
  - 입력토큰에 비해 출력토큰이 3배 비싸다
  - 따라서 방대한 정보를 다룰 때는 RAG가 낫다

## ChatGPT AI 주요 매개변수와 출력

- temperature: 얼마나 창의적이게 할 것인지
- max_tokens: 최대 토큰 수
- model_name: 적용 가능한 모델 리스트
